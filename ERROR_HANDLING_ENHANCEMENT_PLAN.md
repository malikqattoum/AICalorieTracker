# ðŸš¨ Error Handling & Monitoring Enhancement Plan

## Executive Summary

This document outlines a comprehensive strategy for enhancing error handling and monitoring systems in the AI Calorie Tracker application. The plan focuses on implementing robust error detection, categorization, recovery mechanisms, and real-time monitoring to improve system reliability and user experience.

## Current Error Handling State

### Existing Error Handling Components
1. **Basic Error Middleware**: Simple error handling in Express
2. **Custom Error Classes**: AppError class for application-specific errors
3. **Basic Logging**: Console-based error logging
4. **Crash Reporting**: Basic crash reporter service
5. **Error Tracking**: Simple error tracking service

### Identified Gaps
- Lack of centralized error handling
- Insufficient error categorization and severity levels
- No real-time error monitoring
- Limited error recovery mechanisms
- Poor error context and debugging information
- No integration with external monitoring services

## Enhanced Error Handling Architecture

### 1. Centralized Error Handling System

#### 1.1 Error Hierarchy and Categorization

```typescript
// Enhanced error hierarchy
export class AppError extends Error {
  constructor(
    public message: string,
    public statusCode: number = 500,
    public isOperational: boolean = true,
    public severity: ErrorSeverity = 'medium',
    public category: ErrorCategory = 'system',
    public code: string = 'INTERNAL_ERROR',
    public userMessage: string = message,
    public recovery: string = 'Please try again later',
    public metadata?: Record<string, any>
  ) {
    super(message);
    Object.setPrototypeOf(this, new.target.prototype);
    this.name = this.constructor.name;
    Error.captureStackTrace(this, this.constructor);
  }

  toJSON() {
    return {
      name: this.name,
      message: this.message,
      statusCode: this.statusCode,
      severity: this.severity,
      category: this.category,
      code: this.code,
      userMessage: this.userMessage,
      recovery: this.recovery,
      metadata: this.metadata,
      stack: this.stack,
      timestamp: new Date().toISOString()
    };
  }
}

export enum ErrorSeverity {
  LOW = 'low',
  MEDIUM = 'medium',
  HIGH = 'high',
  CRITICAL = 'critical'
}

export enum ErrorCategory {
  AUTH = 'authentication',
  VALIDATION = 'validation',
  DATABASE = 'database',
  API = 'api',
  AI = 'ai-service',
  FILE = 'file',
  NETWORK = 'network',
  SYSTEM = 'system',
  UNKNOWN = 'unknown'
}

// Specific error types
export class ValidationError extends AppError {
  constructor(message: string, field?: string) {
    super(
      message,
      400,
      true,
      ErrorSeverity.MEDIUM,
      ErrorCategory.VALIDATION,
      'VALIDATION_ERROR',
      'Invalid input data',
      'Please check your input and try again',
      { field }
    );
  }
}

export class AuthenticationError extends AppError {
  constructor(message: string = 'Authentication failed') {
    super(
      message,
      401,
      true,
      ErrorSeverity.HIGH,
      ErrorCategory.AUTH,
      'AUTHENTICATION_ERROR',
      'Authentication required',
      'Please log in again'
    );
  }
}

export class DatabaseError extends AppError {
  constructor(message: string, operation?: string) {
    super(
      message,
      503,
      true,
      ErrorSeverity.CRITICAL,
      ErrorCategory.DATABASE,
      'DATABASE_ERROR',
      'Service temporarily unavailable',
      'Please try again later',
      { operation }
    );
  }
}

export class AIServiceError extends AppError {
  constructor(message: string, provider?: string) {
    super(
      message,
      502,
      true,
      ErrorSeverity.HIGH,
      ErrorCategory.AI,
      'AI_SERVICE_ERROR',
      'Analysis service unavailable',
      'The analysis service may be busy. Please try again',
      { provider }
    );
  }
}
```

#### 1.2 Enhanced Error Middleware

```typescript
// Comprehensive error handling middleware
export class ErrorHandler {
  private static logger: winston.Logger;

  static initialize(logger: winston.Logger): void {
    this.logger = logger;
  }

  static handle(
    error: any,
    req: Request,
    res: Response,
    next: NextFunction
  ): void {
    // Convert unknown errors to AppError
    const appError = this.normalizeError(error);
    
    // Add request context
    const errorContext = this.createErrorContext(req, appError);
    
    // Log the error
    this.logError(appError, errorContext);
    
    // Determine recovery strategy
    const recovery = this.getRecoveryStrategy(appError);
    
    // Send error response
    this.sendErrorResponse(res, appError, recovery);
  }

  private static normalizeError(error: any): AppError {
    if (error instanceof AppError) {
      return error;
    }

    // Handle specific error types
    if (error.name === 'ValidationError') {
      return new ValidationError(error.message);
    }

    if (error.name === 'UnauthorizedError' || error.message.includes('unauthorized')) {
      return new AuthenticationError();
    }

    if (error.code === 'ER_DUP_ENTRY' || error.code === '23505') {
      return new ValidationError('Resource already exists', 'unique');
    }

    if (error.code === 'ECONNREFUSED' || error.code === 'ETIMEDOUT') {
      return new AppError(
        'Network connection failed',
        503,
        true,
        ErrorSeverity.HIGH,
        ErrorCategory.NETWORK,
        'NETWORK_ERROR',
        'Service temporarily unavailable',
        'Please check your connection and try again'
      );
    }

    // Handle AI service errors
    if (error.message?.includes('OpenAI') || error.message?.includes('Gemini')) {
      return new AIServiceError(error.message);
    }

    // Handle database errors
    if (error.code?.startsWith('ER_') || error.sql) {
      return new DatabaseError(error.message, error.sql);
    }

    // Default error
    return new AppError(
      error.message || 'Internal server error',
      error.statusCode || 500,
      true,
      ErrorSeverity.MEDIUM,
      ErrorCategory.UNKNOWN,
      'INTERNAL_ERROR',
      'Something went wrong',
      'Our team has been notified. Please try again later'
    );
  }

  private static createErrorContext(req: Request, error: AppError): any {
    return {
      requestId: req.headers['x-request-id'],
      userId: (req as any).user?.id,
      sessionId: (req as any).sessionId,
      userAgent: req.headers['user-agent'],
      ip: req.ip,
      method: req.method,
      url: req.url,
      query: req.query,
      params: req.params,
      body: this.sanitizeRequestBody(req.body),
      timestamp: new Date().toISOString(),
      environment: process.env.NODE_ENV,
      version: process.env.APP_VERSION,
      error: {
        name: error.name,
        message: error.message,
        stack: error.stack,
        code: error.code,
        category: error.category,
        severity: error.severity
      }
    };
  }

  private static sanitizeRequestBody(body: any): any {
    if (!body) return null;
    
    // Remove sensitive information
    const sensitiveFields = ['password', 'token', 'secret', 'key'];
    const sanitized = { ...body };
    
    sensitiveFields.forEach(field => {
      if (sanitized[field]) {
        sanitized[field] = '***REDACTED***';
      }
    });
    
    return sanitized;
  }

  private static logError(error: AppError, context: any): void {
    const logData = {
      ...context,
      error: error.toJSON(),
      duration: Date.now() - context.timestamp
    };

    switch (error.severity) {
      case ErrorSeverity.CRITICAL:
        this.logger.error('Critical error occurred', logData);
        break;
      case ErrorSeverity.HIGH:
        this.logger.error('High severity error', logData);
        break;
      case ErrorSeverity.MEDIUM:
        this.logger.warn('Medium severity error', logData);
        break;
      case ErrorSeverity.LOW:
        this.logger.info('Low severity error', logData);
        break;
    }

    // Send to external monitoring service
    this.sendToMonitoringService(error, context);
  }

  private static getRecoveryStrategy(error: AppError): string {
    const recoveryStrategies: Record<ErrorCategory, string> = {
      [ErrorCategory.AUTH]: 'Please check your credentials and try again',
      [ErrorCategory.VALIDATION]: 'Please validate your input and resubmit',
      [ErrorCategory.DATABASE]: 'Please try again in a few moments',
      [ErrorCategory.API]: 'Please refresh the page and try again',
      [ErrorCategory.AI]: 'The analysis service may be busy. Please try again',
      [ErrorCategory.FILE]: 'Please check your file and try again',
      [ErrorCategory.NETWORK]: 'Please check your connection and try again',
      [ErrorCategory.SYSTEM]: 'Our team has been notified. Please try again later',
      [ErrorCategory.UNKNOWN]: 'Please try again later'
    };

    return recoveryStrategies[error.category] || error.recovery;
  }

  private static sendErrorResponse(
    res: Response,
    error: AppError,
    recovery: string
  ): void {
    const response = {
      success: false,
      error: {
        code: error.code,
        message: error.userMessage,
        severity: error.severity,
        category: error.category,
        recovery,
        timestamp: new Date().toISOString()
      },
      ...(process.env.NODE_ENV === 'development' && {
        debug: {
          stack: error.stack,
          originalError: error.message
        }
      })
    };

    res.status(error.statusCode).json(response);
  }

  private static async sendToMonitoringService(
    error: AppError,
    context: any
  ): Promise<void> {
    try {
      // Integration with external monitoring services
      const monitoringData = {
        ...error.toJSON(),
        context,
        environment: process.env.NODE_ENV,
        version: process.env.APP_VERSION
      };

      // Send to Sentry, Datadog, or similar service
      // await sentry.captureException(error, { extra: context });
      // await datadog.logs.error(error.message, { error, context });

      // For now, log to console for demonstration
      console.log('Monitoring Service:', JSON.stringify(monitoringData, null, 2));
    } catch (monitoringError) {
      console.error('Failed to send error to monitoring service:', monitoringError);
    }
  }
}
```

### 2. Real-time Error Monitoring System

#### 2.1 Error Monitoring Service

```typescript
// Real-time error monitoring with WebSocket integration
export class ErrorMonitoringService {
  private static instance: ErrorMonitoringService;
  private clients: Set<any> = new Set();
  private errorQueue: any[] = [];
  private isProcessing = false;
  private metrics: ErrorMetrics = {
    total: 0,
    byCategory: {},
    bySeverity: {},
    byHour: {},
    topErrors: []
  };

  static getInstance(): ErrorMonitoringService {
    if (!ErrorMonitoringService.instance) {
      ErrorMonitoringService.instance = new ErrorMonitoringService();
    }
    return ErrorMonitoringService.instance;
  }

  addClient(client: any): void {
    this.clients.add(client);
    this.sendInitialMetrics(client);
  }

  removeClient(client: any): void {
    this.clients.delete(client);
  }

  async trackError(error: any, context?: any): Promise<void> {
    const errorEvent = {
      id: crypto.randomUUID(),
      timestamp: new Date().toISOString(),
      severity: this.categorizeSeverity(error),
      category: this.categorizeCategory(error),
      message: error.message,
      stack: error.stack,
      context,
      metadata: {
        userAgent: context?.userAgent,
        userId: context?.userId,
        endpoint: context?.endpoint,
        duration: context?.duration
      }
    };

    // Update metrics
    this.updateMetrics(errorEvent);

    // Add to queue
    this.errorQueue.push(errorEvent);

    // Process queue if not already processing
    if (!this.isProcessing) {
      this.processErrorQueue();
    }
  }

  private async processErrorQueue(): Promise<void> {
    this.isProcessing = true;

    while (this.errorQueue.length > 0) {
      const errorEvent = this.errorQueue.shift();
      
      // Broadcast to connected clients
      this.broadcastError(errorEvent);

      // Send to external monitoring service
      await this.sendToMonitoringService(errorEvent);

      // Throttle to avoid overwhelming the system
      await new Promise(resolve => setTimeout(resolve, 100));
    }

    this.isProcessing = false;
  }

  private broadcastError(errorEvent: any): void {
    const message = JSON.stringify({
      type: 'error',
      data: errorEvent
    });

    this.clients.forEach(client => {
      if (client.readyState === WebSocket.OPEN) {
        client.send(message);
      }
    });
  }

  private async sendToMonitoringService(errorEvent: any): Promise<void> {
    try {
      // Integration with external monitoring services
      // await sentry.captureException(errorEvent);
      // await datadog.logs.error(errorEvent.message, { error: errorEvent });
      
      // For demonstration, log to console
      console.log('External Monitoring:', errorEvent);
    } catch (error) {
      console.error('Failed to send error to monitoring service:', error);
    }
  }

  private categorizeSeverity(error: any): ErrorSeverity {
    if (error.statusCode >= 500) return ErrorSeverity.CRITICAL;
    if (error.statusCode >= 400) return ErrorSeverity.HIGH;
    if (error.statusCode >= 300) return ErrorSeverity.MEDIUM;
    return ErrorSeverity.LOW;
  }

  private categorizeCategory(error: any): ErrorCategory {
    if (error.name?.includes('Auth')) return ErrorCategory.AUTH;
    if (error.name?.includes('Validation')) return ErrorCategory.VALIDATION;
    if (error.name?.includes('Database')) return ErrorCategory.DATABASE;
    if (error.name?.includes('AI')) return ErrorCategory.AI;
    if (error.name?.includes('File')) return ErrorCategory.FILE;
    if (error.code?.includes('ECONN') || error.code?.includes('ETIMEDOUT')) {
      return ErrorCategory.NETWORK;
    }
    return ErrorCategory.UNKNOWN;
  }

  private updateMetrics(errorEvent: any): void {
    this.metrics.total++;

    // By category
    this.metrics.byCategory[errorEvent.category] = 
      (this.metrics.byCategory[errorEvent.category] || 0) + 1;

    // By severity
    this.metrics.bySeverity[errorEvent.severity] = 
      (this.metrics.bySeverity[errorEvent.severity] || 0) + 1;

    // By hour
    const hour = new Date(errorEvent.timestamp).getHours();
    this.metrics.byHour[hour] = (this.metrics.byHour[hour] || 0) + 1;

    // Top errors
    const errorKey = `${errorEvent.category}:${errorEvent.message}`;
    const existingError = this.metrics.topErrors.find(e => e.key === errorKey);
    
    if (existingError) {
      existingError.count++;
    } else {
      this.metrics.topErrors.push({
        key: errorKey,
        category: errorEvent.category,
        message: errorEvent.message,
        count: 1
      });
    }

    // Keep only top 10 errors
    this.metrics.topErrors.sort((a, b) => b.count - a.count);
    this.metrics.topErrors = this.metrics.topErrors.slice(0, 10);
  }

  private sendInitialMetrics(client: any): void {
    const metricsMessage = JSON.stringify({
      type: 'metrics',
      data: this.metrics
    });

    if (client.readyState === WebSocket.OPEN) {
      client.send(metricsMessage);
    }
  }

  getMetrics(): ErrorMetrics {
    return { ...this.metrics };
  }

  getErrorTrends(hours: number = 24): ErrorTrend[] {
    const trends: ErrorTrend[] = [];
    const now = new Date();
    
    for (let i = hours - 1; i >= 0; i--) {
      const hour = new Date(now.getTime() - i * 60 * 60 * 1000);
      const hourKey = hour.getHours();
      
      trends.push({
        timestamp: hour.toISOString(),
        hour: hourKey,
        total: this.metrics.byHour[hourKey] || 0,
        byCategory: Object.entries(this.metrics.byCategory).reduce((acc, [cat, count]) => {
          acc[cat] = (this.metrics.byHour[hourKey] || 0) * (count / this.metrics.total);
          return acc;
        }, {} as Record<string, number>)
      });
    }
    
    return trends;
  }
}

interface ErrorMetrics {
  total: number;
  byCategory: Record<string, number>;
  bySeverity: Record<string, number>;
  byHour: Record<number, number>;
  topErrors: Array<{
    key: string;
    category: string;
    message: string;
    count: number;
  }>;
}

interface ErrorTrend {
  timestamp: string;
  hour: number;
  total: number;
  byCategory: Record<string, number>;
}
```

#### 2.2 Error Dashboard

```typescript
// Real-time error dashboard component
export class ErrorDashboard {
  private monitoringService: ErrorMonitoringService;

  constructor() {
    this.monitoringService = ErrorMonitoringService.getInstance();
  }

  getDashboardData(): DashboardData {
    const metrics = this.monitoringService.getMetrics();
    const trends = this.monitoringService.getErrorTrends();

    return {
      metrics,
      trends,
      health: this.calculateHealthScore(metrics),
      alerts: this.generateAlerts(metrics),
      recommendations: this.generateRecommendations(metrics)
    };
  }

  private calculateHealthScore(metrics: ErrorMetrics): number {
    const totalErrors = metrics.total;
    const criticalErrors = metrics.bySeverity[ErrorSeverity.CRITICAL] || 0;
    const highErrors = metrics.bySeverity[ErrorSeverity.HIGH] || 0;

    // Calculate health score (0-100)
    let score = 100;
    
    // Deduct points for errors
    score -= Math.min(totalErrors * 0.1, 50);
    score -= criticalErrors * 5;
    score -= highErrors * 2;

    return Math.max(0, Math.round(score));
  }

  private generateAlerts(metrics: ErrorMetrics): Alert[] {
    const alerts: Alert[] = [];

    // Critical error threshold
    if ((metrics.bySeverity[ErrorSeverity.CRITICAL] || 0) > 10) {
      alerts.push({
        type: 'critical',
        message: 'High number of critical errors detected',
        timestamp: new Date().toISOString()
      });
    }

    // High error rate
    const totalErrors = Object.values(metrics.bySeverity).reduce((a, b) => a + b, 0);
    if (totalErrors > 100) {
      alerts.push({
        type: 'warning',
        message: 'High error rate detected',
        timestamp: new Date().toISOString()
      });
    }

    // Database errors
    if ((metrics.byCategory[ErrorCategory.DATABASE] || 0) > 20) {
      alerts.push({
        type: 'warning',
        message: 'High number of database errors',
        timestamp: new Date().toISOString()
      });
    }

    return alerts;
  }

  private generateRecommendations(metrics: ErrorMetrics): string[] {
    const recommendations: string[] = [];

    // Check for common error patterns
    if (metrics.byCategory[ErrorCategory.NETWORK] > 10) {
      recommendations.push('Consider implementing better error handling for network requests');
    }

    if (metrics.byCategory[ErrorCategory.VALIDATION] > 15) {
      recommendations.push('Review input validation logic to reduce validation errors');
    }

    if (metrics.byCategory[ErrorCategory.AI] > 5) {
      recommendations.push('Monitor AI service performance and consider adding fallback mechanisms');
    }

    // Check for top errors
    const topError = metrics.topErrors[0];
    if (topError && topError.count > 5) {
      recommendations.push(`Address recurring error: ${topError.message}`);
    }

    return recommendations;
  }
}

interface DashboardData {
  metrics: ErrorMetrics;
  trends: ErrorTrend[];
  health: number;
  alerts: Alert[];
  recommendations: string[];
}

interface Alert {
  type: 'critical' | 'warning' | 'info';
  message: string;
  timestamp: string;
}
```

### 3. Error Recovery Mechanisms

#### 3.1 Retry and Circuit Breaker Pattern

```typescript
// Retry mechanism with exponential backoff
export class RetryService {
  private static maxRetries = 3;
  private static baseDelay = 1000; // 1 second

  static async executeWithRetry<T>(
    operation: () => Promise<T>,
    options: {
      maxRetries?: number;
      baseDelay?: number;
      shouldRetry?: (error: any) => boolean;
    } = {}
  ): Promise<T> {
    const maxRetries = options.maxRetries ?? this.maxRetries;
    const baseDelay = options.baseDelay ?? this.baseDelay;
    const shouldRetry = options.shouldRetry ?? this.defaultShouldRetry;

    let lastError: any;

    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        return await operation();
      } catch (error) {
        lastError = error;

        if (!shouldRetry(error) || attempt === maxRetries) {
          throw error;
        }

        const delay = baseDelay * Math.pow(2, attempt);
        await this.sleep(delay);
      }
    }

    throw lastError;
  }

  private static defaultShouldRetry(error: any): boolean {
    // Retry on network errors and 5xx server errors
    return (
      error.code === 'ECONNREFUSED' ||
      error.code === 'ETIMEDOUT' ||
      (error.statusCode && error.statusCode >= 500)
    );
  }

  private static sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// Circuit breaker pattern
export class CircuitBreaker {
  private state: 'closed' | 'open' | 'half-open' = 'closed';
  private failureCount = 0;
  private failureThreshold = 5;
  private timeout = 60000; // 1 minute
  private nextAttempt = 0;

  constructor(
    private operation: () => Promise<any>,
    private options: {
      failureThreshold?: number;
      timeout?: number;
    } = {}
  ) {
    this.failureThreshold = options.failureThreshold ?? this.failureThreshold;
    this.timeout = options.timeout ?? this.timeout;
  }

  async execute(): Promise<any> {
    if (this.state === 'open') {
      if (Date.now() < this.nextAttempt) {
        throw new Error('Circuit breaker is open');
      } else {
        this.state = 'half-open';
      }
    }

    try {
      const result = await this.operation();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }

  private onSuccess(): void {
    this.failureCount = 0;
    this.state = 'closed';
  }

  private onFailure(): void {
    this.failureCount++;

    if (this.failureCount >= this.failureThreshold) {
      this.state = 'open';
      this.nextAttempt = Date.now() + this.timeout;
    }
  }
}
```

#### 3.2 Fallback Mechanisms

```typescript
// Fallback service for failed operations
export class FallbackService {
  private static fallbackStrategies: Map<string, () => Promise<any>> = new Map();

  static registerFallback(operation: string, strategy: () => Promise<any>): void {
    this.fallbackStrategies.set(operation, strategy);
  }

  static async executeWithFallback<T>(
    operation: string,
    primaryOperation: () => Promise<T>,
    options: {
      timeout?: number;
      shouldFallback?: (error: any) => boolean;
    } = {}
  ): Promise<T> {
    const timeout = options.timeout ?? 5000;
    const shouldFallback = options.shouldFallback ?? this.defaultShouldFallback;

    try {
      // Set timeout for primary operation
      const timeoutPromise = new Promise<never>((_, reject) => {
        setTimeout(() => reject(new Error('Operation timeout')), timeout);
      });

      return await Promise.race([primaryOperation(), timeoutPromise]);
    } catch (error) {
      if (shouldFallback(error)) {
        const fallback = this.fallbackStrategies.get(operation);
        if (fallback) {
          console.log(`Executing fallback for ${operation}`);
          return fallback() as Promise<T>;
        }
      }
      throw error;
    }
  }

  private static defaultShouldFallback(error: any): boolean {
    return (
      error.code === 'ECONNREFUSED' ||
      error.code === 'ETIMEDOUT' ||
      (error.statusCode && error.statusCode >= 500)
    );
  }
}

// Register fallback strategies
FallbackService.registerFallback('ai-analysis', async () => {
  // Return cached nutrition data if available
  return {
    foodName: 'Unknown Food',
    calories: 0,
    protein: 0,
    carbs: 0,
    fat: 0,
    fiber: 0,
    confidence: 0,
    cached: true
  };
});

FallbackService.registerFallback('database-query', async () => {
  // Return cached data or default values
  return [];
});

FallbackService.registerFallback('external-api', async () => {
  // Return mock data for external APIs
  return { success: false, message: 'Service unavailable' };
});
```

### 4. Enhanced Logging System

#### 4.1 Structured Logging

```typescript
// Enhanced structured logging system
export class StructuredLogger {
  private static logger: winston.Logger;

  static initialize(): void {
    this.logger = winston.createLogger({
      level: process.env.LOG_LEVEL || 'info',
      format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.errors({ stack: true }),
        winston.format.json(),
        winston.format.metadata()
      ),
      defaultMeta: { 
        service: 'ai-calorie-tracker',
        environment: process.env.NODE_ENV,
        version: process.env.APP_VERSION
      },
      transports: [
        new winston.transports.File({ 
          filename: 'logs/error.log', 
          level: 'error',
          maxsize: 5242880, // 5MB
          maxFiles: 5
        }),
        new winston.transports.File({ 
          filename: 'logs/combined.log',
          maxsize: 5242880, // 5MB
          maxFiles: 5
        }),
        new winston.transports.Console({
          format: winston.format.combine(
            winston.format.colorize(),
            winston.format.simple()
          ),
          level: process.env.NODE_ENV === 'production' ? 'warn' : 'debug'
        })
      ]
    });
  }

  static info(message: string, meta?: any): void {
    this.logger.info(message, meta);
  }

  static warn(message: string, meta?: any): void {
    this.logger.warn(message, meta);
  }

  static error(message: string, error?: any, meta?: any): void {
    this.logger.error(message, { error: error?.stack || error, ...meta });
  }

  static debug(message: string, meta?: any): void {
    this.logger.debug(message, meta);
  }

  static performance(operation: string, duration: number, meta?: any): void {
    this.logger.info(`Performance: ${operation} completed in ${duration}ms`, {
      operation,
      duration,
      category: 'performance',
      ...meta
    });
  }

  static security(event: string, meta?: any): void {
    this.logger.warn(`Security: ${event}`, {
      event,
      category: 'security',
      ...meta
    });
  }

  static audit(action: string, meta?: any): void {
    this.logger.info(`Audit: ${action}`, {
      action,
      category: 'audit',
      timestamp: new Date().toISOString(),
      ...meta
    });
  }
}
```

#### 4.2 Request Logging Middleware

```typescript
// Request logging middleware
export class RequestLogger {
  private static logger = StructuredLogger;

  static logRequest(req: Request, res: Response, next: NextFunction): void {
    const startTime = Date.now();

    // Log request
    this.logger.info('Incoming request', {
      method: req.method,
      url: req.url,
      userAgent: req.headers['user-agent'],
      ip: req.ip,
      userId: (req as any).user?.id,
      sessionId: (req as any).sessionId
    });

    // Override end method to log response
    const originalEnd = res.end;
    res.end = function(chunk: any, encoding: any) {
      const duration = Date.now() - startTime;
      
      // Log response
      RequestLogger.logger.info('Outgoing response', {
        method: req.method,
        url: req.url,
        statusCode: res.statusCode,
        duration,
        contentLength: res.get('content-length')
      });

      originalEnd.call(this, chunk, encoding);
    };

    next();
  }
}
```

### 5. Integration with External Monitoring Services

#### 5.1 Sentry Integration

```typescript
// Sentry integration for error tracking
export class SentryIntegration {
  private static initialized = false;

  static initialize(): void {
    if (this.initialized) return;

    if (process.env.SENTRY_DSN) {
      Sentry.init({
        dsn: process.env.SENTRY_DSN,
        environment: process.env.NODE_ENV,
        release: process.env.APP_VERSION,
        integrations: [
          new Sentry.Integrations.Http({ tracing: true }),
          new Sentry.Integrations.Express({ middleware: true })
        ],
        tracesSampleRate: 1.0,
        debug: process.env.NODE_ENV === 'development'
      });

      this.initialized = true;
    }
  }

  static captureError(error: any, context?: any): void {
    if (!this.initialized) return;

    Sentry.captureException(error, {
      extra: context,
      tags: {
        environment: process.env.NODE_ENV,
        service: 'ai-calorie-tracker'
      }
    });
  }

  static captureMessage(message: string, level: Sentry.Severity = 'info', context?: any): void {
    if (!this.initialized) return;

    Sentry.captureMessage(message, {
      level,
      extra: context,
      tags: {
        environment: process.env.NODE_ENV,
        service: 'ai-calorie-tracker'
      }
    });
  }
}
```

#### 5.2 Datadog Integration

```typescript
// Datadog integration for metrics and logs
export class DatadogIntegration {
  private static initialized = false;

  static initialize(): void {
    if (this.initialized) return;

    if (process.env.DATADOG_API_KEY) {
      const dogstatsd = require('dogstatsd')({
        host: process.env.DATADOG_HOST || 'localhost',
        port: process.env.DATADOG_PORT || 8125,
        prefix: 'ai-calorie-tracker',
        globalTags: {
          environment: process.env.NODE_ENV,
          service: 'ai-calorie-tracker'
        }
      });

      this.dogstatsd = dogstatsd;
      this.initialized = true;
    }
  }

  private static dogstatsd: any;

  static increment(metric: string, tags?: Record<string, string>): void {
    if (!this.initialized) return;
    this.dogstatsd.increment(metric, 1, tags);
  }

  static decrement(metric: string, tags?: Record<string, string>): void {
    if (!this.initialized) return;
    this.dogstatsd.decrement(metric, 1, tags);
  }

  static histogram(metric: string, value: number, tags?: Record<string, string>): void {
    if (!this.initialized) return;
    this.dogstatsd.histogram(metric, value, tags);
  }

  static gauge(metric: string, value: number, tags?: Record<string, string>): void {
    if (!this.initialized) return;
    this.dogstatsd.gauge(metric, value, tags);
  }

  static set(metric: string, value: string, tags?: Record<string, string>): void {
    if (!this.initialized) return;
    this.dogstatsd.set(metric, value, tags);
  }

  static timing(metric: string, value: number, tags?: Record<string, string>): void {
    if (!this.initialized) return;
    this.dogstatsd.timing(metric, value, tags);
  }
}
```

## Implementation Timeline

### Phase 1: Core Error Handling (Week 1)
- [ ] Implement enhanced error hierarchy
- [ ] Create centralized error middleware
- [ ] Set up structured logging
- [ ] Add request logging middleware

### Phase 2: Real-time Monitoring (Week 2)
- [ ] Implement error monitoring service
- [ ] Create WebSocket-based dashboard
- [ ] Add error metrics and trends
- [ ] Set up alerting system

### Phase 3: Recovery Mechanisms (Week 3)
- [ ] Implement retry service
- [ ] Add circuit breaker pattern
- [ ] Create fallback mechanisms
- [ ] Set up health checks

### Phase 4: External Integration (Week 4)
- [ ] Integrate with Sentry
- [ ] Add Datadog metrics
- [ ] Set up external monitoring
- [ ] Create cross-service error tracking

## Success Metrics

### Error Handling Metrics
- **Error Resolution Time**: < 5 minutes for critical errors
- **Error Detection Rate**: 100% of all errors detected
- **Error Classification Accuracy**: > 95% correct categorization
- **Recovery Success Rate**: > 90% for recoverable errors

### Monitoring Metrics
- **Real-time Alerting**: < 1 second for critical errors
- **Dashboard Update Frequency**: < 5 seconds
- **Error Tracking Coverage**: 100% of all services
- **External Integration Uptime**: 99.9%

### System Reliability Metrics
- **Error Rate Reduction**: 50% reduction in recurring errors
- **System Stability**: 99.9% uptime
- **User Experience Impact**: < 1% of requests affected by errors
- **Recovery Time**: < 30 seconds for service disruptions

## Monitoring Dashboard Features

### Real-time Error Tracking
- Live error stream with categorization
- Error severity visualization
- Error trend analysis
- Top error identification

### System Health Monitoring
- Service health status
- Performance metrics
- Resource utilization
- Error rate tracking

### Alert Management
- Configurable alert thresholds
- Multi-channel notifications
- Alert escalation rules
- Alert history and tracking

### Reporting and Analytics
- Error reports by category/severity
- Performance analysis
- Trend identification
- Root cause analysis

## Conclusion

This comprehensive error handling and monitoring enhancement plan will transform the AI Calorie Tracker application's error management capabilities. By implementing centralized error handling, real-time monitoring, robust recovery mechanisms, and external service integration, the system will achieve:

1. **Improved Reliability**: Faster error detection and resolution
2. **Better User Experience**: Minimal impact from errors with graceful recovery
3. **Enhanced Debugging**: Comprehensive error context and tracking
4. **Proactive Monitoring**: Real-time alerts and trend analysis
5. **Scalable Architecture**: Ready for future growth and expansion

The implementation follows industry best practices and provides a solid foundation for maintaining a high-quality, reliable service.

---

*This plan should be reviewed and updated regularly based on system performance and user feedback.*